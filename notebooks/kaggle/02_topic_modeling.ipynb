{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ““ Notebook 2: Topic Modeling (Customer Voice)\n",
                "\n",
                "**Goal:** Discover themes in Reviews (Size, Fit, Material) and Support data (Shipping, Billing, Tech Support).\n",
                "**Input:** `all_chunks.parquet`, `embeddings.npy`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q bertopic umap-learn hdbscan plotly"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from bertopic import BERTopic\n",
                "from umap import UMAP\n",
                "from hdbscan import HDBSCAN\n",
                "import os\n",
                "\n",
                "# â”€â”€â”€ 1. LOAD DATA â”€â”€â”€\n",
                "\n",
                "# Adjust path to where you uploaded the dataset/output from NB1\n",
                "INPUT_DIR = \"/kaggle/input/customer-voice-processed-nb1\"  \n",
                "OUTPUT_DIR = \"/kaggle/working\"\n",
                "\n",
                "# Fallback check\n",
                "if not os.path.exists(INPUT_DIR):\n",
                "    # Often Kaggle just mounts it at /kaggle/input/dataset-name\n",
                "    # Try current directory first if running linearly\n",
                "    if os.path.exists(\"/kaggle/working/all_chunks.parquet\"):\n",
                "        INPUT_DIR = \"/kaggle/working\"\n",
                "    else:\n",
                "        print(\"Warning: Input dataset not found. Please check paths.\")\n",
                "\n",
                "try:\n",
                "    df = pd.read_parquet(f\"{INPUT_DIR}/all_chunks.parquet\")\n",
                "    embeddings = np.load(f\"{INPUT_DIR}/embeddings.npy\")\n",
                "    docs = df['text'].tolist()\n",
                "    print(f\"Loaded {len(docs)} items.\")\n",
                "except Exception as e:\n",
                "    print(f\"Data Load Error: {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# â”€â”€â”€ 2. CONFIGURE MODEL â”€â”€â”€\n",
                "# Custom seeds for e-commerce & support\n",
                "seeds = [\n",
                "    # Product Issues (Reviews)\n",
                "    [\"wrong size\", \"too small\", \"too large\", \"fit\", \"sizing\"],\n",
                "    [\"material\", \"fabric\", \"quality\", \"texture\", \"cheap\"],\n",
                "    [\"color\", \"design\", \"style\", \"look\", \"pattern\"],\n",
                "    # Support Issues (Tweets)\n",
                "    [\"shipping\", \"delivery\", \"late\", \"package\", \"tracking\"],\n",
                "    [\"refund\", \"return\", \"exchange\", \"charge\", \"billing\"],\n",
                "    [\"app code\", \"login\", \"password\", \"crash\", \"error\"]\n",
                "]\n",
                "\n",
                "umap_model = UMAP(n_neighbors=15, n_components=5, metric='cosine', random_state=42)\n",
                "hdbscan_model = HDBSCAN(min_cluster_size=20, metric='euclidean', prediction_data=True)\n",
                "\n",
                "topic_model = BERTopic(\n",
                "    embedding_model=\"sentence-transformers/all-mpnet-base-v2\",\n",
                "    umap_model=umap_model,\n",
                "    hdbscan_model=hdbscan_model,\n",
                "    seed_topic_list=seeds,\n",
                "    verbose=True\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# â”€â”€â”€ 3. TRAIN â”€â”€â”€\n",
                "# Subsample if too large (>100k)\n",
                "if len(docs) > 100000:\n",
                "    print(\"Subsampling for training (first 50k)...\")\n",
                "    topic_model.fit(docs[:50000], embeddings=embeddings[:50000])\n",
                "    topics, probs = topic_model.transform(docs, embeddings=embeddings)\n",
                "else:\n",
                "    topics, probs = topic_model.fit_transform(docs, embeddings=embeddings)\n",
                "\n",
                "freq = topic_model.get_topic_info()\n",
                "print(freq.head(10))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# â”€â”€â”€ 4. EXPORT â”€â”€â”€\n",
                "topic_model.save(\"/kaggle/working/bertopic_model\", serialization=\"safetensors\", save_ctfidf=True)\n",
                "df['topic'] = topics\n",
                "df.to_parquet(\"/kaggle/working/chunks_with_topics.parquet\")\n",
                "\n",
                "# Visualization\n",
                "try:\n",
                "    fig = topic_model.visualize_topics()\n",
                "    fig.write_html(\"/kaggle/working/topic_map.html\")\n",
                "    fig.show()\n",
                "except Exception as e:\n",
                "    print(f\"Viz error: {e}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}