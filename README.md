# Customer Voice Intelligence ğŸ—£ï¸

> **Turn millions of customer reviews and support tickets into actionable business intelligence â€” in seconds.**

[![Python](https://img.shields.io/badge/Python-3.11+-3776AB?logo=python&logoColor=white)](https://python.org)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-FF4B4B?logo=streamlit&logoColor=white)](https://streamlit.io)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-009688?logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com)
[![HuggingFace](https://img.shields.io/badge/ğŸ¤—-Transformers-FFD21E)](https://huggingface.co)
[![ChromaDB](https://img.shields.io/badge/ChromaDB-Vector_DB-orange)](https://trychroma.com)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## ğŸ¯ What This Is

A **production-grade NLP system** that extracts real, actionable insights from two high-signal customer datasets:

| Dataset | Source | Scale |
|:---|:---|:---|
| ğŸ‘— **Women's E-Commerce Clothing Reviews** | [Kaggle](https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews) | 23,000 real reviews |
| ğŸ¦ **Customer Support on Twitter** | [Kaggle](https://www.kaggle.com/datasets/thoughtvector/customer-support-on-twitter) | 3M+ real tweets |

This is **not** a basic positive/negative sentiment classifier. It's a system that answers real business questions:

- *"What sizing issues are customers reporting for our dresses?"*
- *"Which support issues are most likely to escalate?"*
- *"What do customers love vs. hate about our knitwear?"*

---

## âœ¨ Key Capabilities

| Feature | Description |
|:---|:---|
| ğŸ” **Semantic Search** | Natural language queries across 20,000+ indexed documents using vector similarity |
| ğŸ—‚ï¸ **Topic Modeling** | BERTopic discovers 41 distinct themes (sizing, fabric, shipping, billing, etc.) automatically |
| ğŸ¤– **Zero-Shot Classification** | BART-large-MNLI categorizes support tickets into Shipping / Billing / Tech / Complaint â€” no training data needed |
| ğŸ“ **Sizing Intelligence** | Rule-based + ML analysis to detect "Runs Small", "True to Size", "Runs Large" patterns |
| ğŸ“Š **Evaluation Dashboard** | c-TF-IDF coherence scores, confidence distributions, cluster quality metrics |
| ğŸ”— **RAG Q&A** | Ask questions, get answers grounded in real customer text |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   DATA PIPELINE (Kaggle)                 â”‚
â”‚                                                         â”‚
â”‚  ğŸ“¦ Notebook 1          ğŸ“¦ Notebook 2       ğŸ“¦ Notebook 3â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  Load Reviews           BERTopic            Zero-Shot   â”‚
â”‚  Load Tweets      â”€â”€â”€â–¶  Topic Modeling â”€â”€â”€â–¶ Classificationâ”‚
â”‚  Embed (mpnet)          41 Clusters         Sizing Analysisâ”‚
â”‚  â†’ all_chunks.parquet   â†’ topics.json       â†’ CSVs      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼  (download & import locally)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LOCAL APPLICATION                     â”‚
â”‚                                                         â”‚
â”‚  import_kaggle_data.py                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                 â”‚
â”‚  Loads parquet + embeddings into ChromaDB               â”‚
â”‚                                                         â”‚
â”‚  ChromaDB (Vector Store)                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                              â”‚
â”‚  20,093 documents indexed                               â”‚
â”‚  Cosine similarity search                               â”‚
â”‚  Metadata filtering (source, category, issue_type)      â”‚
â”‚                                                         â”‚
â”‚  Streamlit Dashboard (4 pages)                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”‚
â”‚  ğŸ” Universal Search  â”‚  ğŸ‘— Product Insights            â”‚
â”‚  ğŸ¦ Support Ops       â”‚  ğŸ“Š Evaluation                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tech Stack

| Layer | Technology | Purpose |
|:---|:---|:---|
| **Embeddings** | `sentence-transformers/all-mpnet-base-v2` | 768-dim semantic vectors |
| **Vector DB** | ChromaDB | Persistent local vector store |
| **Topic Modeling** | BERTopic + UMAP + HDBSCAN | Unsupervised theme discovery |
| **Classification** | `facebook/bart-large-mnli` | Zero-shot issue categorization |
| **Backend** | FastAPI + Pydantic | REST API with type safety |
| **Frontend** | Streamlit | Interactive analytics dashboard |
| **Deployment** | Docker + Docker Compose | Containerized full stack |
| **Data Pipeline** | Kaggle Notebooks | GPU-accelerated preprocessing |

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- ~4GB disk space (for models + data)
- Kaggle account (for data download)

### 1. Clone & Install

```bash
git clone https://github.com/your-username/customer-voice-intelligence.git
cd customer-voice-intelligence

python -m venv venv
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

pip install -r requirements.txt
```

### 2. Get the Data (Kaggle Pipeline)

The heavy computation runs on Kaggle's free GPUs. Follow these steps:

**Step 1 â€” Run Notebook 1 (Data + Embeddings)**
1. Upload `notebooks/kaggle/01_data_processing_embeddings.ipynb` to Kaggle
2. Add datasets:
   - `nicapotato/womens-ecommerce-clothing-reviews`
   - `thoughtvector/customer-support-on-twitter`
3. Run all cells â†’ Download `all_chunks.parquet` + `embeddings.npy`

**Step 2 â€” Run Notebook 2 (Topic Modeling)**
1. Upload `notebooks/kaggle/02_topic_modeling.ipynb`
2. Add your Notebook 1 output as a dataset
3. Run all cells â†’ Download `bertopic_model/` folder + `chunks_with_topics.parquet`

**Step 3 â€” Run Notebook 3 (Insights)**
1. Upload `notebooks/kaggle/03_insight_extraction.ipynb`
2. Add your Notebook 1 output as a dataset
3. Run all cells â†’ Download `tweet_issues.csv` + `sizing_analysis.csv`

### 3. Place Downloaded Files

```
data/
â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ all_chunks.parquet          â† from Notebook 1
â”‚   â”œâ”€â”€ embeddings.npy              â† from Notebook 1
â”‚   â””â”€â”€ insights/
â”‚       â”œâ”€â”€ tweet_issues.csv        â† from Notebook 3
â”‚       â””â”€â”€ sizing_analysis.csv     â† from Notebook 3
â””â”€â”€ models/
    â””â”€â”€ bertopic_model/             â† folder from Notebook 2
        â”œâ”€â”€ config.json
        â”œâ”€â”€ topics.json
        â”œâ”€â”€ ctfidf.safetensors
        â””â”€â”€ topic_embeddings.safetensors
```

### 4. Import into ChromaDB

```bash
python scripts/import_kaggle_data.py
# âœ… Import complete. Total docs in collection: 20,093
```

### 5. Launch the Dashboard

```bash
python -m streamlit run streamlit_demo/app.py
# Open: http://localhost:8501
```

---

## ğŸ“Š Dashboard Pages

### ğŸ” Universal Search
Natural language queries across all 20,000+ documents. Filter by source (reviews vs. tweets).

> *Try: "dress sizing issues", "shipping delays", "refund problems"*

### ğŸ‘— Product Insights
- Sizing feedback distribution (Runs Small / True to Size / Runs Large)
- Star rating breakdown from real reviews
- Aspect-based search by product category (Dresses, Jeans, Blouses, etc.)

### ğŸ¦ Support Ops
- Ticket volume by issue type (Shipping / Billing / Tech / Complaint)
- Classification confidence histogram
- "Find Similar Tickets" â€” paste a tweet, get historically similar cases

### ğŸ“Š Evaluation
- **BERTopic Cluster Sizes** â€” 41 discovered topics with document counts
- **Topic Coherence** â€” c-TF-IDF scores proving cluster distinctiveness
- **Classification Confidence** â€” per-issue-type reliability analysis
- **Sizing Signal Coverage** â€” % of reviews with actionable feedback

---

## ğŸ§ª Evaluation Results

| Metric | Result |
|:---|:---|
| Topics Discovered (BERTopic) | **41 coherent clusters** |
| Largest Topic | **Dress reviews** (most discussed category) |
| High-Confidence Tweets (â‰¥70%) | **Measured from real data** |
| Sizing Signal Coverage | **Measured from real data** |
| Semantic Search | Cosine similarity via `all-mpnet-base-v2` |

> ğŸ’¡ All metrics are computed from **real data** and visible in the Evaluation dashboard page.

---

## ğŸ—‚ï¸ Project Structure

```
customer-voice-intelligence/
â”‚
â”œâ”€â”€ ğŸ““ notebooks/kaggle/
â”‚   â”œâ”€â”€ 01_data_processing_embeddings.ipynb  # Load, clean, embed (Kaggle GPU)
â”‚   â”œâ”€â”€ 02_topic_modeling.ipynb              # BERTopic with domain seeds
â”‚   â””â”€â”€ 03_insight_extraction.ipynb          # Zero-shot + sizing analysis
â”‚
â”œâ”€â”€ ğŸ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ main.py                          # FastAPI app (CORS, health checks)
â”‚   â”‚   â””â”€â”€ routers/
â”‚   â”‚       â”œâ”€â”€ search.py                    # Semantic search + RAG Q&A
â”‚   â”‚       â”œâ”€â”€ company.py                   # Company-level insights
â”‚   â”‚       â”œâ”€â”€ trends.py                    # Topic trend analysis
â”‚   â”‚       â”œâ”€â”€ compare.py                   # Side-by-side comparison
â”‚   â”‚       â””â”€â”€ analyze.py                   # Upload & analyze endpoint
â”‚   â”œâ”€â”€ retrieval/
â”‚   â”‚   â”œâ”€â”€ vector_store.py                  # ChromaDB abstraction
â”‚   â”‚   â””â”€â”€ search_engine.py                 # Hybrid search + re-ranking
â”‚   â”œâ”€â”€ insights/
â”‚   â”‚   â”œâ”€â”€ risk_detector.py                 # Zero-shot BART classification
â”‚   â”‚   â”œâ”€â”€ confidence_analyzer.py           # Confidence scoring
â”‚   â”‚   â”œâ”€â”€ competitive_intel.py             # NER + sentiment
â”‚   â”‚   â””â”€â”€ trend_tracker.py                 # Temporal trend analysis
â”‚   â”œâ”€â”€ synthesis/
â”‚   â”‚   â”œâ”€â”€ summarizer.py                    # RAG pipeline
â”‚   â”‚   â”œâ”€â”€ llm_client.py                    # OpenAI abstraction
â”‚   â”‚   â””â”€â”€ prompts.py                       # Prompt templates
â”‚   â”œâ”€â”€ topic_modeling/
â”‚   â”‚   â””â”€â”€ bertopic_pipeline.py             # BERTopic with seed topics
â”‚   â”œâ”€â”€ processing/
â”‚   â”‚   â””â”€â”€ chunker.py                       # Semantic text chunking
â”‚   â””â”€â”€ ingestion/
â”‚       â”œâ”€â”€ api_client.py                    # Data ingestion client
â”‚       â””â”€â”€ regex_parser.py                  # Text parsing utilities
â”‚
â”œâ”€â”€ ğŸ–¥ï¸ streamlit_demo/
â”‚   â””â”€â”€ app.py                               # 4-page interactive dashboard
â”‚
â”œâ”€â”€ ğŸ“œ scripts/
â”‚   â”œâ”€â”€ import_kaggle_data.py                # Load Kaggle outputs â†’ ChromaDB
â”‚   â””â”€â”€ analyze_exports.py                   # Local analysis utilities
â”‚
â”œâ”€â”€ ğŸ§ª tests/
â”‚   â””â”€â”€ test_system.py                       # Comprehensive test suite
â”‚
â”œâ”€â”€ ğŸ“ data/                                 # (gitignored â€” see Quick Start)
â”‚   â”œâ”€â”€ raw/                                 # Parquet + embeddings
â”‚   â”œâ”€â”€ models/                              # BERTopic model files
â”‚   â””â”€â”€ embeddings/                          # ChromaDB persistence
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ LICENSE
```

---

## ğŸ³ Docker Deployment

```bash
# Full stack (API + Streamlit)
docker-compose up --build

# API only
docker build -t customer-voice-api .
docker run -p 8000:8000 customer-voice-api
```

---

## ğŸ”Œ API Reference

The FastAPI backend exposes a REST API (Swagger UI at `/docs`):

| Method | Endpoint | Description |
|:---|:---|:---|
| `POST` | `/api/search` | Semantic search with optional source/category filters |
| `POST` | `/api/search/ask` | RAG-powered Q&A |
| `GET` | `/api/health` | Health check |

### Example: Search

```bash
curl -X POST http://localhost:8000/api/search \
  -H "Content-Type: application/json" \
  -d '{
    "query": "dress sizing issues",
    "n_results": 5,
    "source_filter": "clothing_reviews"
  }'
```

### Example: Ask a Question

```bash
curl -X POST http://localhost:8000/api/search/ask \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What are the most common complaints about shipping?",
    "source_filter": "twitter_support"
  }'
```

---

## ğŸ§ª Running Tests

```bash
pytest tests/ -v
```

---

## ğŸ’¡ Business Use Cases

| Persona | How They Use This |
|:---|:---|
| **Product Manager** | Search "sizing complaints for dresses" â†’ prioritize fit improvements |
| **Support Lead** | View ticket clusters â†’ identify systemic issues before they escalate |
| **Buyer / Merchandiser** | Check sizing distribution per category â†’ adjust size charts |
| **Data Analyst** | Evaluation page â†’ validate model quality before presenting to stakeholders |

---

## ğŸ¤ Interview Talking Points

- *"Used BERTopic with domain-specific seed topics to discover 41 coherent customer themes from 20,000+ unstructured documents â€” no labeled training data required."*
- *"Implemented zero-shot classification with BART-large-MNLI to categorize support tickets into actionable issue types, showing I can apply NLP without task-specific training data."*
- *"Built an end-to-end data pipeline: Kaggle GPU notebooks for heavy compute â†’ local ChromaDB for retrieval â†’ Streamlit dashboard for business users."*
- *"Included a dedicated Evaluation page showing c-TF-IDF coherence scores and confidence distributions â€” demonstrating I understand that NLP quality goes beyond accuracy metrics."*

---

## ğŸ“ License

MIT â€” see [LICENSE](LICENSE) for details.

---

**Built with** Â· Sentence Transformers Â· ChromaDB Â· BERTopic Â· BART Â· FastAPI Â· Streamlit Â· Docker Â· Kaggle

---

## ğŸ‘¨â€ğŸ’» Author

**Arya Yadav**

---
